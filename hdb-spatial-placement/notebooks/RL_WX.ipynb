{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining some Classic Variables and Values\n",
    "\n",
    "environment_variables = {0: 'road', 1: 'footpath', 2: 'playground', 3: 'passive'}\n",
    "theme_variables = {-1: 'naturalistic', -2: 'manicured'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action space variables\n",
    "#Look into action masking for possible actions\n",
    "\n",
    "# Missing Colour, Trunk texture for NOW\n",
    "class plantSpecies():\n",
    "    def __init__(self, species_id, type, height, radius, sun_requirements, attracted_species, fragrant, fruit_bearing, texture) -> None:\n",
    "        self.species_id = species_id\n",
    "        self.type = type\n",
    "        self.height = height\n",
    "        self.radius = radius\n",
    "        self.sun_requirements = sun_requirements\n",
    "        self.attracted_species = attracted_species\n",
    "        self.fragrant = fragrant\n",
    "        self.fruit_bearing = fruit_bearing\n",
    "        self.texture = texture\n",
    "\n",
    "\n",
    "species1 = plantSpecies(100, 'shrub', 0.5, 2, 'low', None, False, False, 'thin')\n",
    "species2 = plantSpecies(101, 'shrub', 0.75, 3, 'high', 'butterfly', True, True, 'medium')\n",
    "species3 = plantSpecies(102, 'shrub', 1, 3, 'low', 'bee', False, True, 'coarse')\n",
    "species4 = plantSpecies(103, 'tree', 10, 2, 'high', None, None, True, None)\n",
    "species5 = plantSpecies(104, 'tree', 15, 3, 'high', None, None, True, None)\n",
    "species6 = plantSpecies(105, 'tree', 20, 4, 'high', None, None, True, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "# Define Set Environment\n",
    "def create_grid(type, max_size, shape_size, context_value, shape_value):\n",
    "    grid = np.full((max_size, max_size), context_value)\n",
    "    \n",
    "    start_x_value = (max_size - shape_size[0])//2\n",
    "    start_y_value = (max_size - shape_size[1])//2\n",
    "    \n",
    "    if type == 'square':\n",
    "        grid[start_y_value:start_y_value+shape_size[1], start_x_value:start_x_value+shape_size[0]] = shape_value\n",
    "\n",
    "    elif type == 'circle':\n",
    "        for x in range(max_size):\n",
    "            for y in range(max_size):\n",
    "                if (x-start_x_value) **2 + (y - start_y_value)**2 <= shape_size[0]**2:\n",
    "                    grid[y,x] = shape_value\n",
    "\n",
    "    elif type == 'rectangle':\n",
    "        grid[start_y_value:start_y_value+shape_size[1], start_x_value:start_x_value+shape_size[0]] = shape_value\n",
    "\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "# Environment Class\n",
    "class customGridEnv(gym.Env):\n",
    "    def __init__(self, grid):\n",
    "        self.grid_size= grid.shape\n",
    "        self.values = [-1, -2, 100, 101, 102, 103, 104, 105, 0, 1, 2, 3]\n",
    "        self.values_to_index = {value: index for index, value in enumerate(self.values)}\n",
    "        \n",
    "        self.action_to_value = {0: 'moveup', 1: 'moveleft', 2: 'moveright', 3: 'movedown', 4: species1, 5: species2, 6: species3, 7: species4, 8: species5, 9:species6}\n",
    "        self.id_to_species = {100: species1, 101: species2, 102:species3, 103:species4, 104:species5, 105:species6}\n",
    "\n",
    "        self.agent_position = (0, 0)\n",
    "\n",
    "        # Initialize your grid\n",
    "        self.grid = grid\n",
    "        self.initial_grid = grid.copy()\n",
    "\n",
    "        self.action_space = spaces.Discrete(len(self.action_to_value)) \n",
    "        # self.observation_space = spaces.Box(low=-2, high=105, shape=(np.prod(self.grid_size)  *  2 + 2, )) #flattened grid + flattened visited + flattened agent position\n",
    "        self.visited = np.zeros(self.grid_size, dtype=bool)  # False means unvisited\n",
    "        self.observation_space = spaces.Box(low=-2, high=105, shape=self.get_observation().shape)\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self.agent_position = (0,0)\n",
    "        self.visited = np.zeros(self.grid_size, dtype=bool)  # False means unvisited\n",
    "        self.grid = self.initial_grid.copy()  # Reset the grid\n",
    "        return self.get_observation()\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        reward = 0\n",
    "        action_to_take = self.action_to_value[int(action)]\n",
    "\n",
    "        if action_to_take in ['moveup', 'movedown', 'moveleft', 'moveright']:\n",
    "            reward += self.calculate_movement_reward(action_to_take)\n",
    "\n",
    "        else:\n",
    "            reward += self.calculate_design_reward(action_to_take)\n",
    "\n",
    "        terminated = False\n",
    "        return self.get_observation(), reward, terminated,  {}\n",
    "\n",
    "    \n",
    "    def calculate_movement_reward(self, action_to_take):\n",
    "        prev_x, prev_y = self.agent_position\n",
    "        reward = 0\n",
    "        \n",
    "        if action_to_take == 'moveup' and prev_y > 0:\n",
    "            self.agent_position = (prev_x, prev_y-1)\n",
    "\n",
    "        elif action_to_take == 'movedown' and prev_y < self.grid_size[1]-1:\n",
    "            self.agent_position = (prev_x, prev_y+1)\n",
    "\n",
    "        elif action_to_take == 'moveleft' and prev_x > 0:\n",
    "            self.agent_position = (prev_x-1, prev_y)\n",
    "\n",
    "        elif action_to_take == 'moveright' and prev_x < self.grid_size[0]-1:\n",
    "            self.agent_position = (prev_x+1, prev_y)\n",
    "        \n",
    "        else:\n",
    "            # Out of bounds\n",
    "            return -500\n",
    "        \n",
    "        # Reward for visiting\n",
    "        if self.visited[self.agent_position[1], self.agent_position[0]]:\n",
    "            reward = -50\n",
    "\n",
    "        self.visited[self.agent_position[1], self.agent_position[0]] = True\n",
    "        \n",
    "        prev_value = int(self.grid[prev_y, prev_x])\n",
    "        current_value = int(self.grid[self.agent_position[1], self.agent_position[0]])\n",
    "\n",
    "        #Unplanted -> Planted (reward med)           \n",
    "        #Unplantable -> Unplantable (reward med)\n",
    "        if prev_value in [0,1,2,3] and current_value in [0,1,2,3,100,101,102,103,104,105]:\n",
    "            return (150 + reward)\n",
    "\n",
    "        #Unplantable -> Plantable (reward huge)\n",
    "        if prev_value in [0,1,2,3] and current_value not in [0,1,2,3,100,101,102,103,104,105]:\n",
    "            return (250 + reward)\n",
    "\n",
    "        #Plantable -> Unplanted (reward small)\n",
    "        if prev_value in [-1,-2] and current_value in [0,1,2,3]:\n",
    "            return (20+ reward)\n",
    "        \n",
    "        #Plantable -> Planted (reward med)\n",
    "        #Plantable -> Plantable (reward med)\n",
    "        if prev_value in [-1,-2] and current_value in [-1,-2,100,101,102,103,104,105]:\n",
    "            return (75 + reward)\n",
    "        \n",
    "        #Planted -> Planted (reward med)\n",
    "        if prev_value in [100,101,102,103,104,105] and current_value in [100,101,102,103,104,105]:\n",
    "            return (75 + reward)\n",
    "        \n",
    "        #Planted -> Plantable (reward big)\n",
    "        if prev_value in [100,101,102,103,104,105] and current_value in [-1,-2]:\n",
    "            return (150 + reward)\n",
    "        \n",
    "        #Planted -> Unplanted (reward small)\n",
    "        if prev_value in [100,101,102,103,104,105] and current_value in [0,1,2,3]:\n",
    "            return (20 + reward)\n",
    "            \n",
    "    \n",
    "    def calculate_design_reward(self, action_to_take):\n",
    "        radius = action_to_take.radius\n",
    "        return self.check_area(action_to_take.species_id , radius, self.agent_position)\n",
    "\n",
    "\n",
    "    def check_area(self, species_id, radius, center_coord):\n",
    "        reward = 0\n",
    "\n",
    "        for dx in range(-radius, radius+1):\n",
    "            for dy in range(-radius, radius+1):\n",
    "                x, y = center_coord[0] +  dx , center_coord[1] + dy\n",
    "\n",
    "                if x**2 + y **2 <= radius**2:\n",
    "                    if 0 <= x < self.grid_size[1] and 0 <=y < self.grid_size[0]:\n",
    "                        current_value = self.grid[y,x]\n",
    "                        if current_value in [-1, -2]:\n",
    "                            reward += 30\n",
    "                        \n",
    "                        elif current_value in [0,1,2,3]:\n",
    "                            reward -= 100\n",
    "                        \n",
    "                        else:\n",
    "                            reward -= 50\n",
    "\n",
    "                        self.grid[y,x] = species_id\n",
    "\n",
    "                    # Boundary\n",
    "                    else:\n",
    "                        reward -= 500\n",
    "\n",
    "        return reward\n",
    "\n",
    "\n",
    "    # def get_observation(self):\n",
    "    #     flattened_grid = self.grid.flatten()\n",
    "    #     flattened_visited = self.visited.flatten().astype(float)  # Convert boolean to float (0 or 1)\n",
    "    #     agent_x, agent_y = self.agent_position\n",
    "        \n",
    "    #     observation = np.concatenate((flattened_grid, flattened_visited, [agent_x, agent_y]))\n",
    "    #     return observation\n",
    "\n",
    "\n",
    "    def get_observation(self):\n",
    "        # Create a 3D tensor for the observation\n",
    "        agent_channel = np.zeros(self.grid_size)\n",
    "        x, y = self.agent_position\n",
    "        agent_channel[x, y] = 1  # One-hot encode the agent's position\n",
    "        observation = np.stack([\n",
    "            self.grid,  # Channel 1\n",
    "            self.visited,   # Channel 2\n",
    "            agent_channel        # Channel 3\n",
    "        ], axis=0)  # Stack channels along a new dimension\n",
    "        \n",
    "        return observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_grids = [\n",
    "    create_grid('square', 100, (80,80), 0, -1),\n",
    "    create_grid('square', 100, (40,40), 0, -1),\n",
    "    create_grid('rectangle', 100, (80,40), 0, -1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnvSpec(id='dynamic_grid_env', entry_point='customGridEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=None, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='dynamic_grid_env', version=None)\n"
     ]
    }
   ],
   "source": [
    "from gym.envs.registration import register\n",
    "\n",
    "register(\n",
    "    id='dynamic_grid_env',  # This should match your env name in the config\n",
    "    entry_point='customGridEnv',  # Adjust to your environment class path\n",
    ")\n",
    "print(gym.envs.registry['dynamic_grid_env'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(-2.0, 105.0, (3, 100, 100), float32)\n",
      "(array([[[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]]]), -500, False, {})\n"
     ]
    }
   ],
   "source": [
    "env = customGridEnv(create_grid('square', 100, (80,80), 0, -1))\n",
    "print(env.observation_space)\n",
    "env.reset()\n",
    "print(env.step(0))  # Test the first action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cheng\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO, DQN\n",
    "\n",
    "# Define your environment\n",
    "env = customGridEnv(create_grid('square', 100, (80, 80), 0, -1))\n",
    "eval_env = customGridEnv(create_grid('square', 100, (60, 60), 0, -1))\n",
    "# Create the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "modelDQN = DQN(\"MlpPolicy\", env, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_policy(model, env, total_timesteps=1000, num_episodes=5):\n",
    "    total_rewards = 0\n",
    "    for _ in range(num_episodes):\n",
    "        obs = env.reset()\n",
    "        episode_reward = 0\n",
    "        for i in range(total_timesteps):\n",
    "            action, _ = model.predict(obs)\n",
    "            obs, reward, done, _ = env.step(action)\n",
    "            episode_reward += reward\n",
    "        total_rewards += episode_reward\n",
    "    average_reward = total_rewards / num_episodes\n",
    "    return average_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "max_runs = 25\n",
    "total_timesteps = 5000\n",
    "\n",
    "for epoch in range(max_runs):\n",
    "    modelDQN.learn(total_timesteps=total_timesteps, log_interval=total_timesteps)\n",
    "    avg_reward = evaluate_policy(modelDQN, eval_env, total_timesteps)\n",
    "    print(f\"Epoch {epoch+1} done. Average Reward: {avg_reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 done. Average Reward: -570602.0\n",
      "Epoch 2 done. Average Reward: 62041.0\n",
      "Epoch 3 done. Average Reward: -800116.0\n",
      "Epoch 4 done. Average Reward: 146427.0\n",
      "Epoch 5 done. Average Reward: 101817.0\n",
      "Epoch 6 done. Average Reward: 200659.0\n",
      "Epoch 7 done. Average Reward: -7708253.0\n",
      "Epoch 8 done. Average Reward: -7011805.0\n",
      "Epoch 9 done. Average Reward: -6565512.0\n",
      "Epoch 10 done. Average Reward: -6672330.0\n",
      "Epoch 11 done. Average Reward: -6508977.0\n",
      "Epoch 12 done. Average Reward: -5330177.0\n",
      "Epoch 13 done. Average Reward: -4277474.0\n",
      "Epoch 14 done. Average Reward: -2046408.0\n",
      "Epoch 15 done. Average Reward: 236066.0\n",
      "Epoch 16 done. Average Reward: -265616.0\n",
      "Epoch 17 done. Average Reward: 213063.0\n",
      "Epoch 18 done. Average Reward: 175499.0\n",
      "Epoch 19 done. Average Reward: 226887.0\n",
      "Epoch 20 done. Average Reward: 241013.0\n",
      "Epoch 21 done. Average Reward: 192437.0\n",
      "Epoch 22 done. Average Reward: -478203.0\n",
      "Epoch 23 done. Average Reward: 322799.0\n",
      "Epoch 24 done. Average Reward: -9081.0\n",
      "Epoch 25 done. Average Reward: 355925.0\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "max_runs = 25\n",
    "total_timesteps = 5000\n",
    "\n",
    "for epoch in range(max_runs):\n",
    "    model.learn(total_timesteps=total_timesteps, log_interval=total_timesteps)\n",
    "    avg_reward = evaluate_policy(model, eval_env, total_timesteps)\n",
    "    print(f\"Epoch {epoch+1} done. Average Reward: {avg_reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 steps with total reward: 303505\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "\n",
    "total_reward = 0\n",
    "steps = 0\n",
    "\n",
    "for _ in range(5000):\n",
    "    # Get action from the model\n",
    "    action, _ = model.predict(obs)  # Get the predicted action\n",
    "    obs, reward, done, info = env.step(action)  # Step the environment\n",
    "    total_reward += reward  # Accumulate rewards\n",
    "\n",
    "    steps += 1\n",
    "\n",
    "print(f\"{steps} steps with total reward: {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 steps with total reward: 308180\n"
     ]
    }
   ],
   "source": [
    "obs = eval_env.reset()\n",
    "\n",
    "total_reward = 0\n",
    "steps = 0\n",
    "\n",
    "for _ in range(5000):\n",
    "    # Get action from the model\n",
    "    action, _ = model.predict(obs)  # Get the predicted action\n",
    "    obs, reward, done, info = eval_env.step(action)  # Step the environment\n",
    "    total_reward += reward  # Accumulate rewards\n",
    "\n",
    "    steps += 1\n",
    "\n",
    "print(f\"{steps} steps with total reward: {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to visualize the grid with unique colors\n",
    "def plot_colored_grid(env_grid):\n",
    "    # Define the possible values and their corresponding colors\n",
    "    possible_values = [-1, -2, 100, 101, 102, 103, 104, 105, 0, 1, 2, 3]\n",
    "    colors = [\n",
    "        (0.0, 0.0, 0.0),   # Black for -1\n",
    "        (0.5, 0.5, 0.5),   # Gray for -2\n",
    "        (1.0, 0.0, 0.0),   # Red for 100\n",
    "        (0.0, 1.0, 0.0),   # Green for 101\n",
    "        (0.0, 0.0, 1.0),   # Blue for 102\n",
    "        (1.0, 1.0, 0.0),   # Yellow for 103\n",
    "        (1.0, 0.0, 1.0),   # Magenta for 104\n",
    "        (0.0, 1.0, 1.0),   # Cyan for 105\n",
    "        (1.0, 0.5, 0.0),   # Orange for 0\n",
    "        (0.5, 0.5, 0.0),   # Olive for 1\n",
    "        (0.5, 0.0, 0.5),   # Purple for 2\n",
    "        (0.5, 0.5, 0.5),   # Dark Gray for 3\n",
    "    ]\n",
    "\n",
    "    # Create a color map\n",
    "    color_map = {value: color for value, color in zip(possible_values, colors)}\n",
    "    colored_grid = np.zeros((env_grid.shape[0], env_grid.shape[1], 3))\n",
    "\n",
    "\n",
    "    # Fill the colored_grid with corresponding colors\n",
    "    for value, color in color_map.items():\n",
    "        colored_grid[env_grid == value] = color\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(colored_grid)\n",
    "    plt.axis('off')  # Hide the axes\n",
    "    plt.title(\"100x100 Grid with Unique Colors\")\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to plot the grid\n",
    "plot_colored_grid(env.grid)\n",
    "plot_colored_grid(eval_env.grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
